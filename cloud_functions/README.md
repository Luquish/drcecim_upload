# Cloud Functions - Sistema de Procesamiento DrCecim

## ğŸ¯ DescripciÃ³n

Sistema de Google Cloud Functions 2Âª generaciÃ³n que procesa documentos PDF y genera embeddings vectoriales para el chatbot DrCecim. Utiliza PostgreSQL con pgvector como base de datos vectorial y OpenAI para generaciÃ³n de embeddings.

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PDF Upload    â”‚â”€â”€â”€â–¶â”‚  process-pdf-to-     â”‚â”€â”€â”€â–¶â”‚   PostgreSQL    â”‚
â”‚   (GCS Bucket)  â”‚    â”‚     chunks           â”‚    â”‚   + pgvector    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                           â–²
                                â–¼                           â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
                       â”‚ create-embeddings-   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚   from-chunks        â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚     OpenAI API       â”‚
                       â”‚   (Embeddings)       â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Estructura del Proyecto

```
cloud_functions/
â”œâ”€â”€ main.py                          # Entry points de ambas funciones
â”œâ”€â”€ requirements.txt                 # Todas las dependencias
â”œâ”€â”€ common/                          # CÃ³digo compartido
â”‚   â”œâ”€â”€ config/                      # ConfiguraciÃ³n centralizada
â”‚   â”‚   â”œâ”€â”€ settings.py              # Variables de entorno
â”‚   â”‚   â””â”€â”€ logging_config.py        # Sistema de logging
â”‚   â”œâ”€â”€ db/                          # Base de datos
â”‚   â”‚   â”œâ”€â”€ connection.py            # ConexiÃ³n Cloud SQL/Local
â”‚   â”‚   â””â”€â”€ models.py                # Modelos SQLAlchemy
â”‚   â”œâ”€â”€ services/                    # Servicios de negocio
â”‚   â”‚   â”œâ”€â”€ processing_service.py    # Procesamiento PDF
â”‚   â”‚   â”œâ”€â”€ embeddings_service.py    # GeneraciÃ³n embeddings
â”‚   â”‚   â”œâ”€â”€ vector_db_service.py     # Base de datos vectorial
â”‚   â”‚   â”œâ”€â”€ gcs_service.py           # Google Cloud Storage
â”‚   â”‚   â””â”€â”€ status_service.py        # Tracking de estado
â”‚   â””â”€â”€ credentials/                 # Credenciales GCP
â”‚       â””â”€â”€ service-account.json     # Service account
â”œâ”€â”€ test_simple.py                   # Script de pruebas locales
â”œâ”€â”€ test_env/                        # Entorno virtual para tests
â””â”€â”€ deploy_event_driven.sh           # Script de deployment
```

## ğŸš€ Cloud Functions

### 1. `process-pdf-to-chunks`
**ğŸ¯ PropÃ³sito**: Procesa documentos PDF y los convierte en chunks de texto estructurado
- **Trigger**: Subida de archivos PDF a Google Cloud Storage
- **TecnologÃ­a**: Marker-PDF para conversiÃ³n PDFâ†’Markdown
- **Output**: Chunks de texto optimizados para RAG
- **Tiempo**: ~2-5 minutos por documento (dependiendo del tamaÃ±o)

### 2. `create-embeddings-from-chunks`  
**ğŸ¯ PropÃ³sito**: Genera embeddings vectoriales y los almacena en PostgreSQL
- **Trigger**: Procesamiento de chunks completado
- **TecnologÃ­a**: OpenAI text-embedding-3-small
- **Output**: Vectores de 1536 dimensiones en pgvector
- **Tiempo**: ~30 segundos por documento

## ğŸ—„ï¸ Base de Datos - PostgreSQL + pgvector

### ConfiguraciÃ³n Cloud SQL
```sql
-- Habilitar extensiÃ³n pgvector
CREATE EXTENSION IF NOT EXISTS vector;

-- Tabla de documentos
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    filename VARCHAR(255) NOT NULL,
    upload_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    processing_status VARCHAR(50) DEFAULT 'uploaded',
    document_metadata JSONB,
    total_chunks INTEGER,
    total_words INTEGER
);

-- Tabla de embeddings vectoriales  
CREATE TABLE embeddings (
    id SERIAL PRIMARY KEY,
    document_id INTEGER REFERENCES documents(id),
    chunk_index INTEGER NOT NULL,
    content TEXT NOT NULL,
    embedding vector(1536),  -- OpenAI embeddings dimension
    document_metadata JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Ãndice para bÃºsquedas vectoriales eficientes
CREATE INDEX idx_embeddings_vector ON embeddings 
USING ivfflat (embedding vector_cosine_ops) 
WITH (lists = 100);
```

### ConfiguraciÃ³n de ConexiÃ³n
```python
# Cloud SQL (ProducciÃ³n)
CLOUD_SQL_CONNECTION_NAME=proyecto:region:instancia
DB_PRIVATE_IP=false  # IP pÃºblica/privada

# PostgreSQL Local (Testing)  
DB_HOST=localhost
DB_PORT=5432
```

## ğŸš€ Deployment

### Pre-requisitos
```bash
# Habilitar APIs necesarias
gcloud services enable cloudfunctions.googleapis.com
gcloud services enable sqladmin.googleapis.com
gcloud services enable storage.googleapis.com

# Configurar autenticaciÃ³n
gcloud auth login
gcloud config set project TU-PROJECT-ID
```

### Deployment Completo
```bash
# Usar el script automatizado (RECOMENDADO)
./deploy_event_driven.sh
```

### Deployment Manual (Opciones Avanzadas)
```bash
# Function 1: Procesamiento PDF
gcloud functions deploy process-pdf-to-chunks \
  --gen2 \
  --runtime=python311 \
  --region=southamerica-east1 \
  --source=. \
  --entry-point=process_pdf_to_chunks \
  --trigger-event-filters="type=google.cloud.storage.object.v1.finalized" \
  --trigger-event-filters="bucket=TU-BUCKET" \
  --memory=2048MB \
  --timeout=540s \
  --max-instances=1

# Function 2: GeneraciÃ³n de Embeddings  
gcloud functions deploy create-embeddings-from-chunks \
  --gen2 \
  --runtime=python311 \
  --region=southamerica-east1 \
  --source=. \
  --entry-point=create_embeddings_from_chunks \
  --trigger-event-filters="type=google.cloud.storage.object.v1.finalized" \
  --trigger-event-filters="bucket=TU-BUCKET" \
  --memory=1024MB \
  --timeout=300s \
  --max-instances=3
```

## ğŸ§ª Testing Local (RECOMENDADO)

### ConfiguraciÃ³n del Entorno de Pruebas
```bash
# 1. Crear entorno virtual
python3 -m venv test_env
source test_env/bin/activate

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Configurar PostgreSQL local
brew install postgresql@14 pgvector
brew services start postgresql@14
createdb ragdb
psql ragdb -c "CREATE EXTENSION IF NOT EXISTS vector;"
psql ragdb -c "CREATE USER raguser WITH PASSWORD 'DrCecim2024@';"
psql ragdb -c "GRANT ALL PRIVILEGES ON DATABASE ragdb TO raguser;"

# 4. Ejecutar pruebas completas
python3 test_simple.py
```

### âœ… ValidaciÃ³n End-to-End
El script `test_simple.py` verifica:
- âœ… **PDF Processing**: Marker convierte PDF â†’ chunks de texto
- âœ… **Database Connection**: PostgreSQL + pgvector funcionando  
- âœ… **OpenAI API**: GeneraciÃ³n de embeddings exitosa
- âœ… **Vector Storage**: Almacenamiento en base vectorial
- âœ… **ConfiguraciÃ³n Centralizada**: Variables cargadas desde `settings.py` y `.env`

### ğŸ”§ ConfiguraciÃ³n de Variables (.env)
```bash
# Crear archivo .env en cloud_functions/
# REQUERIDO
OPENAI_API_KEY=sk-proj-tu-nueva-api-key
GCS_BUCKET_NAME=tu-bucket-name
GCF_PROJECT_ID=tu-project-id

# OPCIONAL (testing local)
TEST_PDF_PATH=/ruta/a/tu/archivo.pdf  # Para test_simple.py
DB_HOST=localhost                     # PostgreSQL local
DB_USER=raguser
DB_PASS=tu-password
```

### ğŸ“‹ Variables de Entorno

```bash
# === GOOGLE CLOUD ===
GCS_BUCKET_NAME=drcecim-chatbot-storage
GCF_PROJECT_ID=tu-project-id  
GCF_REGION=southamerica-east1
SERVICE_ACCOUNT=tu-service-account@project.iam.gserviceaccount.com

# === OPENAI ===
OPENAI_API_KEY=sk-proj-tu-nueva-api-key
EMBEDDING_MODEL=text-embedding-3-small
API_TIMEOUT=30

# === DATABASE ===
# Cloud SQL (ProducciÃ³n)
CLOUD_SQL_CONNECTION_NAME=proyecto:region:instancia
DB_USER=raguser
DB_PASS=tu-password
DB_NAME=ragdb
DB_PRIVATE_IP=false

# PostgreSQL Local (Testing)
DB_HOST=localhost
DB_PORT=5432

# === PROCESAMIENTO ===
CHUNK_SIZE=250
CHUNK_OVERLAP=50
LOG_LEVEL=INFO
LOG_TO_DISK=false  # Cloud Functions compatible
ENVIRONMENT=production
```

## ğŸ” Monitoreo y Troubleshooting

### Logs de Cloud Functions
```bash
# Ver logs en tiempo real
gcloud functions logs read process-pdf-to-chunks --region=southamerica-east1 --follow

# Logs de una funciÃ³n especÃ­fica
gcloud functions logs read create-embeddings-from-chunks --region=southamerica-east1 --limit=50
```

### Verificar Estado de la Base de Datos
```sql
-- Conectar a Cloud SQL
gcloud sql connect tu-instancia --user=raguser --database=ragdb

-- Verificar datos
SELECT COUNT(*) as total_documentos FROM documents;
SELECT COUNT(*) as total_embeddings FROM embeddings;

-- Ver Ãºltimo documento procesado
SELECT filename, processing_status, upload_timestamp 
FROM documents 
ORDER BY upload_timestamp DESC 
LIMIT 5;
```

### Problemas Comunes

**âŒ Error: Health check failed**
- **Causa**: Archivo `main.py` con errores de sintaxis
- **SoluciÃ³n**: Ejecutar `test_simple.py` antes del deploy

**âŒ Error: Cannot connect to Cloud SQL**  
- **Causa**: Service account sin permisos
- **SoluciÃ³n**: Agregar rol `Cloud SQL Client` al service account

**âŒ Error: OpenAI rate limit**
- **Causa**: LÃ­mites de API superados  
- **SoluciÃ³n**: Configurar `API_TIMEOUT` mÃ¡s alto o usar tier pagado

**âŒ Error: pgvector extension not found**
- **Causa**: ExtensiÃ³n no habilitada en Cloud SQL
- **SoluciÃ³n**: `CREATE EXTENSION IF NOT EXISTS vector;` 