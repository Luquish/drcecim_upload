# Nueva Arquitectura Orientada a Eventos - DrCecim Upload

## Resumen

Este documento describe la nueva arquitectura orientada a eventos implementada para mejorar la robustez, escalabilidad y mantenibilidad del sistema de procesamiento de documentos DrCecim.

## Problemas Resueltos

### üî¥ Problemas de la Arquitectura Anterior
- **Funci√≥n Monol√≠tica**: Una sola funci√≥n manejaba todo el pipeline (PDF ‚Üí Chunks ‚Üí Embeddings ‚Üí GCS)
- **Timeouts**: Documentos grandes pod√≠an exceder los l√≠mites de tiempo de Cloud Functions
- **Falta de Robustez**: Si fallaba cualquier paso, todo el proceso fallaba
- **Escalabilidad Limitada**: No se pod√≠a escalar independientemente cada etapa

### ‚úÖ Ventajas de la Nueva Arquitectura
- **Desacoplamiento**: Cada funci√≥n tiene una responsabilidad espec√≠fica
- **Tolerancia a Fallos**: Si falla una etapa, las otras pueden continuar
- **Escalabilidad Independiente**: Cada funci√≥n puede escalar seg√∫n sus necesidades
- **Procesamiento As√≠ncrono**: No hay esperas bloqueantes para el usuario
- **Mejor Monitoreo**: Cada etapa se puede monitorear independientemente

## Arquitectura

```mermaid
graph TD
    A[Usuario sube PDF] --> B[Cloud Storage Bucket]
    B --> C[üîÑ Evento: PDF Uploaded]
    C --> D[Function 1: process-pdf-to-chunks]
    D --> E[Chunks JSON en processed/]
    E --> F[üîÑ Evento: Chunks Created]
    F --> G[Function 2: create-embeddings-from-chunks]
    G --> H[√çndice FAISS Actualizado]
    G --> I[Metadatos CSV Actualizados]
    
    style D fill:#e1f5fe
    style G fill:#f3e5f5
    style H fill:#e8f5e8
    style I fill:#e8f5e8
```

## Componentes

### 1. Function 1: `process-pdf-to-chunks`

**Responsabilidad**: Convertir PDFs a chunks de texto estructurados.

**Trigger**: Se activa autom√°ticamente cuando se sube un archivo `.pdf` al bucket de Cloud Storage.

**Proceso**:
1. Descarga el PDF desde GCS
2. Usa Marker PDF para extraer y procesar el texto
3. Genera chunks con metadata
4. Sube el archivo `{nombre}_chunks.json` al prefijo `processed/`

**Configuraci√≥n**:
- Memoria: 1024MB
- Timeout: 9 minutos (540s)
- Instancias m√°ximas: 10

### 2. Function 2: `create-embeddings-from-chunks`

**Responsabilidad**: Generar embeddings y actualizar el √≠ndice FAISS global.

**Trigger**: Se activa cuando aparece un archivo `*_chunks.json` en el prefijo `processed/`.

**Proceso**:
1. Descarga el archivo de chunks
2. Genera embeddings usando OpenAI API
3. Descarga el √≠ndice FAISS existente (si existe)
4. Actualiza el √≠ndice de manera incremental
5. Sube el √≠ndice actualizado y metadatos a GCS

**Configuraci√≥n**:
- Memoria: 2048MB
- Timeout: 15 minutos (900s)
- Instancias m√°ximas: 5

## Estructura de Datos

### Bucket Layout
```
gs://tu-bucket/
‚îú‚îÄ‚îÄ documento1.pdf                    # ‚Üê PDFs subidos aqu√≠
‚îú‚îÄ‚îÄ documento2.pdf
‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îú‚îÄ‚îÄ documento1_chunks.json        # ‚Üê Chunks procesados
‚îÇ   ‚îî‚îÄ‚îÄ documento2_chunks.json
‚îú‚îÄ‚îÄ embeddings/
‚îÇ   ‚îî‚îÄ‚îÄ faiss_index.bin              # ‚Üê √çndice FAISS global
‚îî‚îÄ‚îÄ metadata/
    ‚îî‚îÄ‚îÄ metadata.csv                 # ‚Üê Metadatos globales
```

### Formato de Chunks JSON
```json
{
  "filename": "documento1.pdf",
  "source_file": "documento1.pdf",
  "num_chunks": 45,
  "total_words": 1250,
  "processing_timestamp": "2024-01-15T10:30:00Z",
  "chunks": [
    {
      "chunk_id": 0,
      "text": "Contenido del chunk...",
      "word_count": 28,
      "page_numbers": [1, 2]
    }
  ],
  "metadata": {
    "document_type": "academic",
    "language": "es",
    "extraction_method": "marker_pdf"
  }
}
```

## Despliegue

### Prerrequisitos
1. **Variables de entorno** configuradas en `.env`:
   ```bash
   GCF_PROJECT_ID=tu-proyecto-id
   GCS_BUCKET_NAME=tu-bucket
   GCF_REGION=us-central1
   OPENAI_API_KEY=tu-api-key
   ```

2. **Cuenta de servicio** con permisos:
   - Cloud Functions Developer
   - Storage Admin
   - Service Account User

### Comandos de Despliegue

#### Opci√≥n 1: Script Autom√°tico (Recomendado)
```bash
cd cloud_functions
./deploy_event_driven.sh
```

#### Opci√≥n 2: Despliegue Manual
```bash
# Funci√≥n 1
gcloud functions deploy process-pdf-to-chunks \
  --gen2 \
  --runtime=python311 \
  --region=us-central1 \
  --source=. \
  --entry-point=process_pdf_to_chunks \
  --trigger-event-filters="type=google.cloud.storage.object.v1.finalized" \
  --trigger-event-filters="bucket=tu-bucket" \
  --trigger-event-filters-path-pattern="*.pdf" \
  --service-account=chatbot-pipeline-sa@tu-proyecto.iam.gserviceaccount.com

# Funci√≥n 2  
gcloud functions deploy create-embeddings-from-chunks \
  --gen2 \
  --runtime=python311 \
  --region=us-central1 \
  --source=. \
  --entry-point=create_embeddings_from_chunks \
  --trigger-event-filters="type=google.cloud.storage.object.v1.finalized" \
  --trigger-event-filters="bucket=tu-bucket" \
  --trigger-event-filters-path-pattern="processed/*_chunks.json" \
  --service-account=chatbot-pipeline-sa@tu-proyecto.iam.gserviceaccount.com
```

## Uso

### Para Procesar un Documento

1. **Sube el PDF directamente al bucket**:
   ```bash
   gsutil cp mi_documento.pdf gs://tu-bucket/
   ```

2. **El sistema procesar√° autom√°ticamente**:
   - ‚úÖ Function 1 detectar√° el PDF y lo procesar√°
   - ‚úÖ Function 2 detectar√° los chunks y generar√° embeddings
   - ‚úÖ El √≠ndice FAISS se actualizar√° incrementalmente

3. **No hay esperas**: El proceso es completamente as√≠ncrono

### Para la App Streamlit

La app Streamlit ahora puede:
- Subir archivos directamente al bucket usando `GCSService`
- Mostrar un mensaje de "procesamiento iniciado"
- Opcionalmente implementar verificaci√≥n de estado

## Monitoreo

### Logs de Cloud Functions
```bash
# Ver logs de la funci√≥n 1
gcloud functions logs read process-pdf-to-chunks --region=us-central1

# Ver logs de la funci√≥n 2  
gcloud functions logs read create-embeddings-from-chunks --region=us-central1
```

### M√©tricas Importantes
- **Latencia**: Tiempo de procesamiento por documento
- **Errores**: Fallos en cualquiera de las etapas
- **Throughput**: Documentos procesados por hora
- **Costos**: Llamadas a OpenAI API y recursos de GCP

### Health Checks
Ambas funciones exponen endpoints de health check:
```bash
curl https://us-central1-tu-proyecto.cloudfunctions.net/process-pdf-to-chunks/health
curl https://us-central1-tu-proyecto.cloudfunctions.net/create-embeddings-from-chunks/health
```

## Actualizaci√≥n Incremental de FAISS

La nueva arquitectura implementa actualizaci√≥n incremental del √≠ndice FAISS:

1. **Descarga** el √≠ndice existente desde GCS
2. **Combina** los nuevos vectores con los existentes
3. **Actualiza** metadatos concatenando DataFrames
4. **Sube** el √≠ndice actualizado de vuelta a GCS

Esto permite:
- ‚úÖ Mantener un √∫nico √≠ndice global
- ‚úÖ Agregar documentos sin reconstruir todo
- ‚úÖ Preservar la eficiencia de b√∫squeda
- ‚úÖ Reducir costos de procesamiento

## Migraci√≥n desde Arquitectura Anterior

### Funci√≥n Legacy
La funci√≥n original `process_document` en `main.py` sigue disponible pero se considera **legacy**. 

### Coexistencia
- ‚úÖ Ambas arquitecturas pueden coexistir
- ‚úÖ La funci√≥n legacy funciona independientemente  
- ‚úÖ Gradualmente migrar hacia la nueva arquitectura

### Ventajas de Migrar
- üìà **Mayor robustez** ante fallos
- ‚ö° **Mejor escalabilidad** 
- üîß **M√°s f√°cil mantenimiento**
- üí∞ **Potencialmente m√°s econ√≥mico**

## Troubleshooting

### Problemas Comunes

#### 1. PDF no se procesa
- ‚úÖ Verificar que el archivo tenga extensi√≥n `.pdf`
- ‚úÖ Revisar logs de `process-pdf-to-chunks`
- ‚úÖ Verificar permisos del bucket

#### 2. Embeddings no se generan
- ‚úÖ Verificar que aparezca el archivo `*_chunks.json` en `processed/`
- ‚úÖ Revisar API key de OpenAI
- ‚úÖ Verificar logs de `create-embeddings-from-chunks`

#### 3. √çndice FAISS no se actualiza
- ‚úÖ Verificar permisos de escritura en el bucket
- ‚úÖ Revisar espacio disponible
- ‚úÖ Verificar logs para errores de memoria

### Comandos √ötiles

```bash
# Listar archivos en el bucket
gsutil ls -r gs://tu-bucket/

# Ver estado de las funciones
gcloud functions describe process-pdf-to-chunks --region=us-central1
gcloud functions describe create-embeddings-from-chunks --region=us-central1

# Ver m√©tricas de uso
gcloud logging read "resource.type=cloud_function" --limit=50
```

## Pr√≥ximos Pasos

1. **Notificaciones**: Implementar notificaciones cuando el procesamiento complete
2. **Dashboard**: Crear panel de monitoreo en tiempo real  
3. **Retry Logic**: Agregar l√≥gica de reintentos para fallos transitorios
4. **Batching**: Procesar m√∫ltiples documentos en lotes
5. **Optimizaci√≥n**: Ajustar configuraciones bas√°ndose en m√©tricas de uso 